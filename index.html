<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Ounass Look Generator</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <!-- React and Babel for single-file JSX compilation -->
  <script src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
  <script src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
  <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
  
  <!-- Vercel Web Analytics -->
  <script>
    // Load Vercel Analytics script
    (function() {
      var script = document.createElement('script');
      script.src = '/_vercel/insights/script.js';
      script.defer = true;
      document.head.appendChild(script);
      console.log('[Analytics] Vercel script loaded');
    })();
  </script>
  <style>
    body { font-family: 'Inter', sans-serif; }
    input:focus, button:focus, textarea:focus { outline: none; box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.5); }
  </style>
</head>
<body>
  <div id="root"></div>

  <script type="text/babel">
    const { useState, useRef } = React;

    // The main App component containing all logic and UI
    const App = () => {
      const [skus, setSkus] = useState(['', '']);
      const [productImages, setProductImages] = useState({});
      const [selectedImages, setSelectedImages] = useState({});
      const [prompts, setPrompts] = useState({ studio: '', lifestyle: '' });
      const [selectedPrompt, setSelectedPrompt] = useState('studio');
      const [generatedImage, setGeneratedImage] = useState(null);
      const [loadingState, setLoadingState] = useState('IDLE'); // More granular loading state
      const [error, setError] = useState(null);
      const [currentStep, setCurrentStep] = useState(1);
      const [showLifestyleForm, setShowLifestyleForm] = useState(false);
      const [lifestyleInputs, setLifestyleInputs] = useState({ location: '', mood: '', time: '', extra: '' });
      const [showTryOnForm, setShowTryOnForm] = useState(false);
      const [tryOnPhoto, setTryOnPhoto] = useState(null);
    
      // Handle try-on photo upload with compression
      const handleTryOnPhotoUpload = (event) => {
        const file = event.target.files[0];
        if (file) {
          // Check file size (10MB limit for try-on)
          if (file.size > 10 * 1024 * 1024) {
            setError('Photo size must be less than 10MB for try-on');
            return;
          }
          
          // Smart resize for API efficiency while maintaining quality
          const img = new Image();
          img.onload = () => {
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');
            
            // Calculate optimal dimensions (max 1500px on longest side for high quality)
            const maxSize = 1500;
            let { width, height } = img;
            
            if (width > height) {
              if (width > maxSize) {
                height = (height * maxSize) / width;
                width = maxSize;
              }
            } else {
              if (height > maxSize) {
                width = (width * maxSize) / height;
                height = maxSize;
              }
            }
            
            canvas.width = width;
            canvas.height = height;
            
            // High quality resize with good compression balance
            ctx.drawImage(img, 0, 0, width, height);
            
            // Use high quality JPEG (0.85 quality for good balance)
            const optimizedDataURL = canvas.toDataURL('image/jpeg', 0.85);
            
            console.log(`[Photo Upload] Original: ${file.size} bytes (${img.width}x${img.height})`);
            console.log(`[Photo Upload] Optimized: ${optimizedDataURL.length} chars (${width}x${height})`);
            console.log(`[Photo Upload] Size reduction: ${((file.size - optimizedDataURL.length) / file.size * 100).toFixed(1)}%`);
            
            setTryOnPhoto(optimizedDataURL);
            setError(null);
          };
          
          img.onerror = () => {
            setError('Failed to load the uploaded photo');
          };
          
          // Read file as data URL to load into image
          const reader = new FileReader();
          reader.onload = (e) => {
            img.src = e.target.result;
          };
          reader.readAsDataURL(file);
        }
      };
    
      // Helper function to fetch a URL (retry mechanism removed for simplicity)
      const fetchWithRetry = async (url) => {
        try {
          const response = await fetch(url, {
            cache: 'no-cache',
            signal: AbortSignal.timeout(12000)
          });
          
          if (response.ok) {
            return response;
          }
          
          throw new Error(`HTTP ${response.status}: ${response.statusText}`);
        } catch (e) {
          console.error(`[Error] Fetch failed for ${url}: ${e.message}`);
          throw e;
        }
      };
    
      // Fetches images for a given SKU from the Ounass API using a proxy to bypass CORS
      const fetchImages = async () => {
        setError(null);
        setLoadingState('FETCHING_IMAGES');
        
        // Analytics: Track image fetch start (disabled for debugging)
        // window.va?.track('fetch_images_started', {
        //   sku_count: skus.filter(s => s).length
        // });
        const validSkus = skus.filter(s => s);
        
        if (validSkus.length < 2) {
          setError('Please enter at least 2 SKUs.');
          setLoadingState('IDLE');
          return;
        }

        // Logging the start of the process
        console.log(`[Initiating] Starting image fetching process for ${validSkus.length} SKUs.`);
        
        // Performance tracking
        const startTime = performance.now();

        // Creating an array of promises to fetch all SKUs concurrently with timeout
        const fetchPromises = validSkus.map(sku => {
          // 5 different proxy services in waterfall approach
          const proxyServices = [
            {
              name: 'CORS.EU',
              url: `https://cors.eu.org/https://www.ounass.ae/product/findbysku?sku=${sku}`,
              parser: (data) => data
            },
            {
              name: 'AllOrigins',
              url: `https://api.allorigins.win/get?url=${encodeURIComponent(`https://www.ounass.ae/product/findbysku?sku=${sku}`)}`,
              parser: (data) => JSON.parse(data.contents)
            },
            {
              name: 'CORS.SH',
              url: `https://proxy.cors.sh/https://www.ounass.ae/product/findbysku?sku=${sku}`,
              parser: (data) => data
            },
            {
              name: 'ThingProxy',
              url: `https://thingproxy.freeboard.io/fetch/https://www.ounass.ae/product/findbysku?sku=${sku}`,
              parser: (data) => data
            },
            {
              name: 'Direct API',
              url: `https://www.ounass.ae/product/findbysku?sku=${sku}`,
              parser: (data) => data
            }
          ];
          
          console.log(`[Step 1] Sending API request for SKU ${sku} via 5 proxy services.`);
          
          // Add timeout to prevent hanging requests
          const timeoutPromise = new Promise((_, reject) => 
            setTimeout(() => reject(new Error('Request timeout')), 10000) // 10 seconds per proxy
          );
          
          // Waterfall approach: try each proxy until one works
          const tryProxies = async () => {
            for (let i = 0; i < proxyServices.length; i++) {
              const proxy = proxyServices[i];
              try {
                console.log(`[Step 1.${i + 1}] Trying ${proxy.name} for SKU ${sku}`);
                
                const response = await fetch(proxy.url, {
                  cache: 'no-cache',
                  signal: AbortSignal.timeout(10000)
                });
                
                if (response.ok) {
                  const data = await response.json();
                  console.log(`[Success] ${proxy.name} worked for SKU ${sku}`);
                  
                  // Parse data based on proxy type
                  const parsedData = proxy.parser(data);
                  return { response, data: parsedData };
                }
              } catch (e) {
                console.log(`[Warning] ${proxy.name} failed for SKU ${sku}: ${e.message}`);
                if (i === proxyServices.length - 1) throw e;
              }
            }
            throw new Error('All proxy services failed');
          };
          
          const fetchPromise = tryProxies().then(({ response, data }) => {
            // Data is already parsed by the proxy parser
            const content = data;
            const imageSrcs = content.media
              .filter(m => m.mediaType === 'image')
              .map(m => `https://ounass-ae.atgcdn.ae/pub/media/catalog/product${m.src}`);
    
            if (imageSrcs.length > 0) {
              console.log(`[Success] Found ${imageSrcs.length} images for SKU ${sku}.`);
              
              // Log analytics data to see available fields
              console.log(`[Debug] Analytics data for SKU ${sku}:`, content.analytics);
              
              const brand = content.analytics?.brand || 'Unknown Brand';
              const name = content.analytics?.name || 'Unknown Product';
              
              // Build detailed category: department/class/subClass format
              const department = content.analytics?.department || 'Unknown';
              const productClass = content.analytics?.class || '';
              const subClass = content.analytics?.subClass || content.analytics?.subclass || '';
              
              // Build hierarchical category string
              let category = department;
              if (productClass) {
                category += `/${productClass}`;
                if (subClass) {
                  category += `/${subClass}`;
                }
              }
              
              return {
                sku,
                images: {
                  srcs: imageSrcs,
                  description: `${brand} ${name} (${category})`,
                  brand,
                  name,
                  category
                }
              };
            } else {
              console.warn(`[Warning] No images found for SKU ${sku}.`);
              throw new Error(`No images found for SKU ${sku}.`);
            }
          }).catch(e => {
            console.error(`[Error] An error occurred for SKU ${sku}: ${e.message}`);
            return { sku, error: e.message };
          });
          
          // Race between fetch and timeout
          return Promise.race([fetchPromise, timeoutPromise]);
        });

        const results = await Promise.allSettled(fetchPromises);
        let successfulResults = [];
        let firstError = null;
        let finalHasErrors = false;
        
        results.forEach((result, index) => {
          if (result.status === 'fulfilled' && result.value && result.value.images && result.value.images.srcs && result.value.images.srcs.length > 0) {
            successfulResults.push({ sku: result.value.sku, images: result.value.images });
          } else if (result.status === 'rejected' || (result.value && result.value.error)) {
            finalHasErrors = true;
            if (!firstError) {
              firstError = result.reason || (result.value && result.value.error);
            }
          }
        });

        // --- NEW: Re-sort the results based on the original user input order ---
        const sortedImages = validSkus.map(sku => {
          return successfulResults.find(result => result.sku === sku);
        }).filter(Boolean); // Filter out any undefined entries if a SKU failed
        // --- END RE-SORT ---

        const endTime = performance.now();
        const totalTime = Math.round(endTime - startTime);
        
        console.log(`[Completed] Total images for ${sortedImages.length} SKUs successfully fetched in ${totalTime}ms.`);
        
        // Convert array back to object format for compatibility with existing renderStep code
        const productImagesObject = {};
        sortedImages.forEach(item => {
          if (item && item.sku) {
            productImagesObject[item.sku] = item.images;
          }
        });
        
        // Final state update with the correctly sorted array
        setProductImages(productImagesObject);
        setLoadingState('IDLE');
        
        // Smart error handling: prioritize success over errors
        if (sortedImages.length >= 2) {
          // We have enough successful SKUs, clear errors and proceed
          setError(null);
          setCurrentStep(2); // Go to step 2 for image selection
          console.log(`[Success] Proceeding to step 2 with ${sortedImages.length} successful SKUs`);
          
          // Analytics: Track successful image fetch (disabled for debugging)
          // window.va?.track('fetch_images_success', {
          //   successful_skus: sortedImages.length,
          //   total_time_ms: totalTime
          // });
        } else if (sortedImages.length > 0) {
          // Some SKUs succeeded but not enough, show partial success message
          setError(`Only ${sortedImages.length} SKU(s) loaded successfully. Need at least 2 SKUs to proceed.`);
          console.log(`[Debug] Not enough SKUs: ${sortedImages.length} < 2`);
        } else {
          // No SKUs succeeded, show error
          setError(`Failed to fetch images from all proxy services. Please try again.`);
          console.log(`[Debug] No SKUs succeeded: ${sortedImages.length} = 0`);
        }
      };
    
      // AI Creative Director function to inspire lifestyle inputs based on product images
      const inspireLifestyleInputs = async () => {
        try {
          setLoadingState('GENERATING_INSPIRATION');
          
          // Get selected product images for AI analysis
          const selectedImageUrls = Object.keys(selectedImages).map(sku => selectedImages[sku]);
          
          if (selectedImageUrls.length === 0) {
            throw new Error('No product images selected for inspiration');
          }
          
          console.log('[Product-Aware Inspiration] Analyzing', selectedImageUrls.length, 'product images');
          
          // Convert selected image URLs to base64 for AI analysis
          const base64Images = await Promise.all(
            selectedImageUrls.map(async (url) => {
              try {
                const response = await fetch(url);
                const blob = await response.blob();
                return new Promise((resolve) => {
                  const reader = new FileReader();
                  reader.onload = () => resolve(reader.result);
                  reader.readAsDataURL(blob);
                });
              } catch (error) {
                console.error('Failed to convert image to base64:', error);
                return null;
              }
            })
          );
          
          // Filter out failed conversions
          const validImages = base64Images.filter(img => img !== null);
          
          if (validImages.length === 0) {
            throw new Error('Failed to process product images for inspiration');
          }
          
          console.log('[Product-Aware Inspiration] Sending', validImages.length, 'images to AI Art Director');

          const response = await fetch('/api/gemini-inspire', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              images: validImages
            })
          });

          if (!response.ok) {
            throw new Error('Product-aware inspiration failed');
          }

          const result = await response.json();
          
          if (result.success && result.text) {
            // Simple text extraction - no JSON parsing needed
            const text = result.text;
            console.log('[Product-Aware Inspiration] Raw AI response:', text);
            
            const extractAnswer = (questionNumber, label) => {
              // Look for pattern: "1. LOCATION:" or "LOCATION:" followed by the answer
              const patterns = [
                new RegExp(`${questionNumber}\\.\\s*${label}:\\s*(.+?)(?=\\n\\d+\\.|\\n[A-Z]+:|$)`, 'is'),
                new RegExp(`${label}:\\s*(.+?)(?=\\n\\d+\\.|\\n[A-Z]+:|$)`, 'is')
              ];
              
              for (const pattern of patterns) {
                const match = text.match(pattern);
                if (match && match[1]) {
                  const answer = match[1].trim().replace(/^\[|\]$/g, ''); // Remove brackets if present
                  console.log(`[Extraction] ${label}:`, answer.substring(0, 100) + '...');
                  return answer;
                }
              }
              
              console.warn(`[Extraction] ${label}: NOT FOUND`);
              return '';
            };
            
            const inspiration = {
              location: extractAnswer('1', 'LOCATION') || 'A stylish urban setting',
              mood: extractAnswer('2', 'MOOD') || 'Confident and sophisticated', 
              time: extractAnswer('3', 'TIME') || 'Golden hour lighting',
              extra: extractAnswer('4', 'EXTRA') || 'Complementary props and atmosphere'
            };
            
            setLifestyleInputs(inspiration);
            console.log('[Product-Aware Inspiration] âœ¨ Final extracted inspiration:', inspiration);
            
          } else {
            throw new Error(result.error || 'No product-aware inspiration received');
          }
          
        } catch (error) {
          console.error('[Product-Aware Inspiration] Failed:', error);
          
          // Product-aware fallback suggestions (more generic but still thoughtful)
          const productAwareFallbacks = [
            {
              location: 'A modern minimalist studio with natural light',
              mood: 'Clean and sophisticated',
              time: 'Soft daylight through large windows',
              extra: 'Subtle textures and neutral backdrop to highlight the products'
            },
            {
              location: 'An upscale urban cafÃ© with contemporary design',
              mood: 'Relaxed elegance',
              time: 'Warm afternoon light',
              extra: 'Modern furniture and architectural details'
            },
            {
              location: 'A stylish rooftop terrace with city views',
              mood: 'Confident and dynamic',
              time: 'Golden hour with urban backdrop',
              extra: 'Contemporary setting that complements fashion-forward styling'
            }
          ];
          
          const randomInspiration = productAwareFallbacks[Math.floor(Math.random() * productAwareFallbacks.length)];
          setLifestyleInputs(randomInspiration);
          console.log('[Product-Aware Inspiration] âœ¨ Using product-aware fallback:', randomInspiration);
        } finally {
          setLoadingState('IDLE');
        }
      };

      // AI Art Director function to enhance scene descriptions
      const enhanceSceneWithArtDirector = async (location, mood, time, extra) => {
        try {
          const artDirectorPrompt = `You are the world's best fashion photography art director. Transform the following basic scene inputs into a professional, detailed photography scene description.

INPUT DETAILS:
- Location: ${location}
- Mood: ${mood}  
- Time/Lighting: ${time}
- Additional details: ${extra || 'None'}

TASK: Create a detailed, professional scene description that includes:
1. Specific lighting setup and quality
2. Detailed location description and atmosphere
3. Camera angle and composition suggestions
4. Environmental details that enhance the mood
5. Professional photography terminology

REQUIREMENTS:
- Keep it concise but professional (2-3 sentences max)
- Focus on visual and atmospheric elements
- Use professional photography language
- Make it suitable for AI image generation

OUTPUT FORMAT: Only return the enhanced scene description, nothing else.`;

          const response = await fetch('/api/gemini-text', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              prompt: artDirectorPrompt
            })
          });

          if (!response.ok) {
            throw new Error('Art director enhancement failed');
          }

          const result = await response.json();
          
          if (result.success && result.text) {
            // Successfully got enhanced description from AI Art Director
            return result.text.trim();
          } else {
            // Fallback if AI enhancement failed
            throw new Error(result.error || 'No text in response');
          }
          
        } catch (error) {
          console.error('Art director enhancement failed:', error);
          // Fallback to original format if AI enhancement fails
          return `Location: '${location}' with a '${mood}' mood. Lighting: '${time}'. Additional details: ${extra || ''}`;
        }
      };

      // Generates prompts. This is now the single source of truth for prompt creation.
      const generatePrompts = async (isLifestyle = false) => {
        setLoadingState('GENERATING_PROMPTS');
        setError(null);
        
        try {
          // Dynamically build the product reference list based on user's SKU order
          const productDetails = Object.values(productImages).map((p, i) => ({
            ref: `Image ${i + 1}`, // Use the direct index from the user's order
            category: p.category || 'item' // Fallback category
          }));
          const productReferences = productDetails.map(p => `the ${p.category.toLowerCase()} from ${p.ref}`).join(', ');

          // Generate dynamic product specifications based on actual number of products
          const productSpecifications = productDetails.map((detail, index) => 
            `- Image ${index + 1}: ${detail.category} - REPLICATE EXACTLY`
          ).join('\n');

          let finalPrompt = '';
          if (isLifestyle) {
            // Enhance scene description using AI Art Director
            console.log('[Art Director] Enhancing scene description...');
            const enhancedSceneDescription = await enhanceSceneWithArtDirector(
              lifestyleInputs.location,
              lifestyleInputs.mood,
              lifestyleInputs.time,
              lifestyleInputs.extra
            );
            console.log('[Art Director] Enhanced scene:', enhancedSceneDescription);

            // Construct the DYNAMIC lifestyle prompt with AI-enhanced scene
            finalPrompt = `A photorealistic lifestyle photograph of a fashion model. 

CRITICAL REQUIREMENT - PRODUCT PRESERVATION:
The model MUST wear the EXACT products from the provided reference images. These products are NOT to be used as inspiration - they are to be REPLICATED PERFECTLY with zero modifications.

PRODUCT SPECIFICATIONS:
${productSpecifications}

SCENE SETTING:
${enhancedSceneDescription}

FINAL INSTRUCTION:
Copy the products pixel-perfect. Do not create variations. Do not interpret. Do not stylize. REPLICATE EXACTLY as provided.`;
            setPrompts(prev => ({ ...prev, lifestyle: finalPrompt }));
            setShowLifestyleForm(false);
            
            // Analytics: Track lifestyle prompt generation (disabled for debugging)
            // window.va?.track('prompt_generated', {
            //   prompt_type: 'lifestyle',
            //   product_count: productDetails.length,
            //   location: lifestyleInputs.location,
            //   mood: lifestyleInputs.mood,
            //   time: lifestyleInputs.time,
            //   has_extra_details: !!lifestyleInputs.extra
            // });
          } else {
            // Construct the DYNAMIC studio prompt with AGGRESSIVE product preservation
            finalPrompt = `A photorealistic full-body studio photograph of a model.

CRITICAL REQUIREMENT - PRODUCT PRESERVATION:
The model MUST wear the EXACT products from the provided reference images. These products are NOT to be used as inspiration - they are to be REPLICATED PERFECTLY with zero modifications.

PRODUCT SPECIFICATIONS:
${productSpecifications}

STUDIO SETTING:
Pose: Elegant and static.
Background: Seamless light grey.
Lighting: Bright and professional.

FINAL INSTRUCTION:
Copy the products pixel-perfect. Do not create variations. Do not interpret. Do not stylize. REPLICATE EXACTLY as provided.`;
            setPrompts({ studio: finalPrompt, lifestyle: '' });
            setCurrentStep(3);
            
            // Analytics: Track prompt generation (disabled for debugging)
            // window.va?.track('prompt_generated', {
            //   prompt_type: 'studio',
            //   product_count: productDetails.length
            // });
          }
        } catch(e) {
            setError('Failed to construct prompts.');
            console.error(e);
        } finally {
          setLoadingState('IDLE');
        }
      };
      
      // Removed generateLifestylePrompt as it's now merged into generatePrompts
    
      // Helper function to convert a URL to a Base64 string
      const urlToBase64 = async (url) => {
        const startTime = performance.now();
        try {
          const response = await fetch(url);
          const blob = await response.blob();
          
          return new Promise((resolve, reject) => {
            const reader = new FileReader();
            reader.onloadend = () => {
              const endTime = performance.now();
              console.log(`[Timing] Base64 conversion for ${url.substring(0, 50)}... completed in ${Math.round(endTime - startTime)}ms`);
              resolve(reader.result);
            };
            reader.onerror = (error) => {
              const endTime = performance.now();
              console.error(`[Timing] Base64 conversion failed after ${Math.round(endTime - startTime)}ms:`, error);
              reject(error);
            };
            reader.readAsDataURL(blob);
          });
        } catch (error) {
          const endTime = performance.now();
          console.error(`[Timing] Base64 conversion failed after ${Math.round(endTime - startTime)}ms:`, error);
          throw error;
        }
      };
    
    
      // Handles virtual try-on generation
      const handleTryOnGeneration = async () => {
        setError(null);
        setLoadingState('GENERATING_IMAGE');
        
        console.log('[Try-On] Starting virtual try-on generation...');
        const startTime = performance.now();
        
        try {
          // Step 1: Generate smart prompt using Gemini 1.5 Flash
          console.log('[Try-On] Step 1: Generating smart prompt...');
          const promptResponse = await fetch('/api/gemini-prompt-generator', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              productDetails: Object.keys(selectedImages).map(sku => ({
                sku,
                name: productImages[sku].name,
                brand: productImages[sku].brand,
                category: productImages[sku].category
              }))
            })
          });
          
          let generatedPrompt = null;
          if (promptResponse.ok) {
            const promptResult = await promptResponse.json();
            if (promptResult.success) {
              generatedPrompt = promptResult.generatedPrompt;
              console.log('[Try-On] âœ… Smart prompt generated:', generatedPrompt);
            }
          } else {
            console.log('[Try-On] âš ï¸ Prompt generation failed, using fallback');
          }
          
          // Step 2: Convert product images to base64 (original quality)
          const selectedImageUrls = Object.values(selectedImages);
          console.log(`[Try-On] Step 2: Converting ${selectedImageUrls.length} product images to base64...`);
          
          const base64Products = await Promise.all(selectedImageUrls.map(async (url) => {
            return await urlToBase64(url); // No compression - original quality
          }));
          
          // Step 3: Prepare payload with generated prompt
          const tryOnPayload = {
            userPhoto: tryOnPhoto,
            productImages: base64Products,
            productDetails: Object.keys(selectedImages).map(sku => ({
              sku,
              name: productImages[sku].name,
              brand: productImages[sku].brand,
              category: productImages[sku].category
            })),
            generatedPrompt: generatedPrompt // Include the AI-generated prompt
          };
          
          console.log('--- TRY-ON FINAL PAYLOAD TO GEMINI ---');
          console.log('User photo length:', tryOnPhoto.length);
          console.log('User photo format:', tryOnPhoto.substring(0, 50) + '...');
          console.log('Product images count:', base64Products.length);
          base64Products.forEach((img, index) => {
            console.log(`Product ${index + 1} length:`, img.length);
            console.log(`Product ${index + 1} format:`, img.substring(0, 50) + '...');
          });
          console.log('Product details:', tryOnPayload.productDetails);
          
          // Calculate frontend payload size
          const frontendPayload = JSON.stringify(tryOnPayload);
          const frontendSizeMB = (frontendPayload.length / (1024 * 1024)).toFixed(2);
          console.log('Frontend payload size:', frontendSizeMB, 'MB');
          console.log('--- PAYLOAD DATA SENT TO /api/gemini-tryon ---');
          
          console.log('ðŸš¨ ABOUT TO CALL /api/gemini-tryon ðŸš¨');
          console.log('ðŸš¨ API URL: /api/gemini-tryon');
          console.log('ðŸš¨ Method: POST');
          console.log('ðŸš¨ Payload size:', JSON.stringify(tryOnPayload).length, 'chars');
          
          const response = await fetch('/api/gemini-tryon', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(tryOnPayload)
          });
          
          console.log('ðŸš¨ RESPONSE RECEIVED ðŸš¨');
          console.log('ðŸš¨ Response status:', response.status);
          console.log('ðŸš¨ Response ok:', response.ok);

          if (!response.ok) {
            console.log('ðŸš¨ RESPONSE NOT OK - GETTING ERROR DATA ðŸš¨');
            const errorData = await response.json();
            console.log('ðŸš¨ Error data:', errorData);
            throw new Error(errorData.error || 'Virtual try-on failed');
          }
          
          const result = await response.json();
          
          console.log('ðŸš¨ TRY-ON API RESPONSE ANALYSIS ðŸš¨');
          console.log('ðŸš¨ Success:', result.success);
          console.log('ðŸš¨ Has image:', !!result.image);
          console.log('ðŸš¨ Image length:', result.image?.length);
          console.log('ðŸš¨ Debug info:', result.debug);
          console.log('ðŸš¨ AI Response text:', result.aiResponse);
          console.log('ðŸš¨ Full result keys:', Object.keys(result));
          
          // CRITICAL: Display the actual prompt used
          console.log('ðŸ”¥ðŸ”¥ðŸ”¥ PROMPT SENT TO AI ðŸ”¥ðŸ”¥ðŸ”¥');
          console.log(result.prompt);
          console.log('ðŸ”¥ðŸ”¥ðŸ”¥ END OF PROMPT ðŸ”¥ðŸ”¥ðŸ”¥');
          
          if (result.success) {
            setGeneratedImage(result.image);
            setCurrentStep(4);
            const endTime = performance.now();
            console.log(`[Try-On] Virtual try-on completed in ${Math.round(endTime - startTime)}ms`);
          } else {
            console.log('ðŸš¨ TRY-ON FAILED ðŸš¨');
            console.log('ðŸš¨ Error:', result.error);
            console.log('ðŸš¨ AI Text Response:', result.aiResponse);
            
            // CRITICAL: Display prompt even on failure
            console.log('ðŸ”¥ðŸ”¥ðŸ”¥ PROMPT SENT TO AI (ERROR CASE) ðŸ”¥ðŸ”¥ðŸ”¥');
            console.log(result.prompt);
            console.log('ðŸ”¥ðŸ”¥ðŸ”¥ END OF PROMPT ðŸ”¥ðŸ”¥ðŸ”¥');
            
            throw new Error(result.error || 'Failed to generate try-on image');
          }

        } catch (error) {
          console.error('[Try-On] Error:', error);
          setError(`Virtual try-on failed: ${error.message}`);
        } finally {
          setLoadingState('IDLE');
        }
      };
    
      // Handles the final image generation call to the API
      const handleGenerateImage = async () => {
        // Special handling for try-on
        if (selectedPrompt === 'tryon') {
          if (!tryOnPhoto) {
            setError('Please upload your photo for virtual try-on.');
            return;
          }
          return handleTryOnGeneration();
        }
        
        if (!selectedPrompt || !prompts[selectedPrompt]) {
          setError('Please select a prompt.');
          return;
        }
    
        setError(null);
        setLoadingState('UPLOADING_IMAGES');
        
        // Performance tracking
        const startTime = performance.now();
        console.log(`[Timing] Starting image generation process...`);
    
        try {
          console.log(`[Timing] Converting images to base64...`);
          const base64StartTime = performance.now();
          
          const selectedImageUrls = Object.values(selectedImages);
          
          // --- REVERTED: Decoy image technique is removed as it causes a 400 Bad Request ---
          const base64Images = await Promise.all(selectedImageUrls.map(urlToBase64));
          // --- END REVERT ---

          const base64EndTime = performance.now();
          console.log(`[Timing] Base64 conversion completed in ${Math.round(base64EndTime - base64StartTime)}ms`);
          
          // --- CRITICAL DEBUG LOG ---
          console.log('%c--- DATA SENT TO /api/gemini-image ---', 'color: purple; font-weight: bold; font-size: 14px;');
          console.log('%cFinal Prompt:', 'color: purple; font-weight: bold;', prompts[selectedPrompt]);
          console.log('%cImage URLs Sent:', 'color: purple; font-weight: bold;', selectedImageUrls);
          console.log(`%cTotal Images: ${base64Images.length}`, 'color: purple; font-weight: bold;');
          console.log('%c-------------------------------------------', 'color: purple; font-weight: bold; font-size: 14px;');
          // --- END CRITICAL DEBUG LOG ---
          
          setLoadingState('GENERATING_IMAGE');
    
          console.log(`[Timing] Sending image generation request to Gemini API...`);
          const apiStartTime = performance.now();
          
          const response = await fetch('/api/gemini-image', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              prompt: prompts[selectedPrompt],
              images: base64Images
            })
          });

          const apiEndTime = performance.now();
          console.log(`[Timing] Gemini API response received in ${Math.round(apiEndTime - apiStartTime)}ms`);

          if (!response.ok) {
            const errorData = await response.json();
            throw new Error(errorData.error || 'Image generation failed');
          }
          
          const result = await response.json();
          
          if (result.success) {
            // Log the definitive final prompt received back from the server
            if (result.debug && result.debug.finalPrompt) {
              console.log('%c--- DEFINITIVE DATA USED BY AI (from Server) ---', 'color: green; font-weight: bold; font-size: 14px;');
              console.log('Final Prompt:', result.debug.finalPrompt);
              console.log('Image URLs Sent:', selectedImageUrls); // Log the URLs that were sent
              console.log('%c----------------------------------------------------', 'color: green; font-weight: bold; font-size: 14px;');
            }

            setGeneratedImage(result.image);
            setCurrentStep(4);
            const endTime = performance.now();
            console.log(`[Timing] Image generation completed in ${Math.round(endTime - startTime)}ms`);
            console.log(`[Timing] Breakdown: Base64 conversion: ${Math.round(base64EndTime - base64StartTime)}ms, API call: ${Math.round(apiEndTime - apiStartTime)}ms`);
            
            // Analytics: Track successful image generation (disabled for debugging)
            // window.va?.track('image_generated', {
            //   prompt_type: selectedPrompt,
            //   product_count: selectedImageUrls.length,
            //   generation_time_ms: Math.round(endTime - startTime),
            //   api_time_ms: Math.round(apiEndTime - apiStartTime)
            // });
          } else {
            throw new Error(result.error || 'Failed to generate image');
          }
    
        } catch (e) {
            const endTime = performance.now();
            console.error(`[Timing] Image generation failed after ${Math.round(endTime - startTime)}ms:`, e.message);
            setError(`An error occurred while generating the image: ${e.message}`);
        } finally {
          setLoadingState('IDLE');
        }
      };
    
      const handleDownloadImage = () => {
        if (generatedImage) {
          const link = document.createElement('a');
          link.href = generatedImage;
          link.download = 'ounass-look.png';
          document.body.appendChild(link);
          link.click();
          document.body.removeChild(link);
          
          // Analytics: Track image download (disabled for debugging)
          // window.va?.track('image_downloaded', {
          //   prompt_type: selectedPrompt,
          //   file_name: 'ounass-look.png'
          // });
        }
      };
    
      // Resets the application to the first step
      const resetApp = () => {
        setSkus(['', '']);
        setProductImages({});
        setSelectedImages({});
        setPrompts({ studio: '', lifestyle: '' });
        setGeneratedImage(null);
        setError(null);
        setCurrentStep(1);
        setShowLifestyleForm(false);
        setLifestyleInputs({ location: '', mood: '', time: '', extra: '' });
      };
      
      // New function to go back to the prompts screen
      const backToPrompts = () => {
        setError(null);
        setCurrentStep(3);
      };
    
      // Renders a single step of the process
      const renderStep = () => {
        switch (currentStep) {
          case 1:
            return (
              <div className="flex flex-col space-y-4">
                <h2 className="text-xl font-semibold mb-2">1. Enter SKUs (Min 2, Max 5)</h2>
                {skus.map((sku, index) => (
                  <div key={index} className="flex items-center space-x-2">
                    <input
                      type="text"
                      placeholder={`SKU ${index + 1}`}
                      value={sku}
                      onChange={(e) => {
                        const newSkus = [...skus];
                        newSkus[index] = e.target.value;
                        setSkus(newSkus);
                      }}
                      className="flex-1 p-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500"
                    />
                    {skus.length > 2 && (
                      <button
                        onClick={() => setSkus(skus.filter((_, i) => i !== index))}
                        className="p-2 text-red-500 hover:text-red-700 transition-colors"
                      >
                        Remove
                      </button>
                    )}
                  </div>
                ))}
                <div className="flex justify-end space-x-2 mt-4">
                  {skus.length < 5 && (
                    <button
                      onClick={() => setSkus([...skus, ''])}
                      className="p-2 text-blue-500 hover:text-blue-700 transition-colors"
                    >
                      Add SKU
                    </button>
                  )}
                  <button
                    onClick={fetchImages}
                    disabled={skus.filter(s => s).length < 2 || loadingState !== 'IDLE'}
                    className="p-3 bg-blue-600 text-white rounded-lg shadow-md hover:bg-blue-700 transition-all disabled:bg-gray-400 disabled:cursor-not-allowed"
                  >
                    {loadingState === 'FETCHING_IMAGES' ? 'Loading...' : 'Fetch Images'}
                  </button>
                </div>
              </div>
            );
          case 2:
            return (
              <div className="flex flex-col space-y-6">
                <h2 className="text-xl font-semibold mb-2">2. Select Images</h2>
                {Object.keys(productImages).map(sku => (
                  <div key={sku} className="border-b pb-4">
                    <h3 className="text-lg font-medium mb-2">SKU: {sku}</h3>
                    <div className="flex flex-wrap gap-4 justify-center">
                      {productImages[sku].srcs.map((src, index) => (
                        <div
                          key={index}
                          className={`relative w-36 h-36 rounded-lg cursor-pointer overflow-hidden transition-all ${selectedImages[sku] === src ? 'ring-4 ring-blue-500 scale-105' : 'ring-2 ring-transparent hover:ring-blue-300'}`}
                          onClick={() => setSelectedImages(prev => ({ ...prev, [sku]: src }))}
                        >
                          <img src={src} alt={`SKU ${sku} - Image ${index + 1}`} className="w-full h-full object-cover" />
                        </div>
                      ))}
                    </div>
                  </div>
                ))}
                <div className="flex justify-end mt-4">
                  <button
                    onClick={() => generatePrompts(false)}
                    disabled={Object.keys(selectedImages).length !== Object.keys(productImages).length}
                    className="p-3 bg-blue-600 text-white rounded-lg shadow-md hover:bg-blue-700 transition-all disabled:bg-gray-400 disabled:cursor-not-allowed"
                  >
                    Generate Prompts
                  </button>
                </div>
              </div>
            );
          case 3:
            return (
              <div className="flex flex-col space-y-6">
                <h2 className="text-xl font-semibold mb-2">3. Select a Prompt and Generate Image</h2>
                {/* This block was accidentally deleted. Re-adding it to show selected images. */}
                <div className="flex flex-wrap gap-6 mb-8 p-4 bg-gray-100 rounded-xl">
                  {Object.keys(selectedImages).map(sku => (
                    <div key={sku} className="flex-1 min-w-[200px] bg-white p-4 rounded-lg shadow-md flex flex-col items-center text-center">
                      <img src={selectedImages[sku]} alt={`Selected Product ${sku}`} className="w-24 h-24 object-contain mb-2 rounded-md" />
                      <p className="text-sm font-semibold mb-1">Product: {productImages[sku].name}</p>
                      <p className="text-xs text-gray-600">Brand: {productImages[sku].brand}</p>
                      <p className="text-xs text-gray-600">Category: {productImages[sku].category}</p>
                    </div>
                  ))}
                </div>
                <div className="flex flex-col space-y-4">
                  <div>
                    <label className="flex items-center space-x-2 cursor-pointer">
                      <input
                        type="radio"
                        name="prompt"
                        value="studio"
                        checked={selectedPrompt === 'studio'}
                        onChange={(e) => { 
                          setSelectedPrompt(e.target.value); 
                          setShowLifestyleForm(false); 
                          setShowTryOnForm(false); 
                        }}
                        className="form-radio text-blue-600"
                      />
                      <span className="font-medium text-lg">Studio Shoot Prompt</span>
                    </label>
                    {selectedPrompt === 'studio' && (
                      <textarea
                        value={prompts.studio}
                        onChange={(e) => setPrompts(prev => ({ ...prev, studio: e.target.value }))}
                        className="bg-gray-100 p-4 mt-2 rounded-lg text-sm text-gray-700 w-full h-24 resize-none focus:outline-none focus:ring-2 focus:ring-blue-500"
                        placeholder="Edit the prompt here..."
                      />
                    )}
                  </div>
                  <div>
                    <label className="flex items-center space-x-2 cursor-pointer">
                      <input
                        type="radio"
                        name="prompt"
                        value="lifestyle"
                        checked={selectedPrompt === 'lifestyle'}
                        onChange={(e) => {
                          setSelectedPrompt(e.target.value);
                          setShowTryOnForm(false);
                          setShowLifestyleForm(true);
                        }}
                        className="form-radio text-blue-600"
                      />
                      <span className="font-medium text-lg">Lifestyle Shoot Prompt</span>
                    </label>
                    {selectedPrompt === 'lifestyle' && (showLifestyleForm ? (
                      <div className="bg-gray-100 p-4 mt-2 rounded-lg text-sm text-gray-700 w-full">
                        <div className="flex justify-between items-center mb-4">
                          <div>
                            <h3 className="font-semibold text-gray-800">Lifestyle Scene Details</h3>
                            <p className="text-xs text-gray-500 mt-1">AI will analyze your selected products to suggest matching scenes</p>
                          </div>
                          <button
                            onClick={inspireLifestyleInputs}
                            disabled={loadingState === 'GENERATING_INSPIRATION'}
                            className="px-3 py-1.5 bg-purple-500 text-white text-xs rounded-lg hover:bg-purple-600 transition-all disabled:opacity-50 disabled:cursor-not-allowed flex items-center space-x-1"
                          >
                            {loadingState === 'GENERATING_INSPIRATION' ? (
                              <>
                                <div className="w-3 h-3 border border-white border-t-transparent rounded-full animate-spin"></div>
                                <span>Analyzing...</span>
                              </>
                            ) : (
                              <>
                                <span>ðŸŽ¨</span>
                                <span>Inspire Me</span>
                              </>
                            )}
                          </button>
                        </div>
                        <div className="flex flex-col space-y-2 mb-4">
                          <input
                            type="text"
                            placeholder="Location (e.g., 'a bustling city street')"
                            value={lifestyleInputs.location}
                            onChange={(e) => setLifestyleInputs(prev => ({ ...prev, location: e.target.value }))}
                            className="p-2 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
                          />
                          <input
                            type="text"
                            placeholder="Mood (e.g., 'energetic and vibrant')"
                            value={lifestyleInputs.mood}
                            onChange={(e) => setLifestyleInputs(prev => ({ ...prev, mood: e.target.value }))}
                            className="p-2 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
                          />
                          <input
                            type="text"
                            placeholder="Time of Day (e.g., 'golden hour at sunset')"
                            value={lifestyleInputs.time}
                            onChange={(e) => setLifestyleInputs(prev => ({ ...prev, time: e.target.value }))}
                            className="p-2 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
                          />
                          <textarea
                            placeholder="Extra details? (e.g., 'rainy weather, with an umbrella')"
                            value={lifestyleInputs.extra}
                            onChange={(e) => setLifestyleInputs(prev => ({ ...prev, extra: e.target.value }))}
                            className="p-2 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500 resize-none h-20"
                          />
                        </div>
                        <button
                          onClick={() => generatePrompts(true)}
                          className="w-full p-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600 transition-all"
                        >
                          Generate Prompt
                        </button>
                      </div>
                    ) : (
                      <textarea
                        value={prompts.lifestyle}
                        onChange={(e) => setPrompts(prev => ({ ...prev, lifestyle: e.target.value }))}
                        className="bg-gray-100 p-4 mt-2 rounded-lg text-sm text-gray-700 w-full h-24 resize-none focus:outline-none focus:ring-2 focus:ring-blue-500"
                        placeholder="Click 'Generate Prompt' to create a custom lifestyle prompt based on your inputs..."
                      />
                    ))}
                  </div>
                  
                  {/* Try On Yourself Option */}
                  <div>
                    <label className="flex items-center space-x-2 cursor-pointer">
                      <input
                        type="radio"
                        name="prompt"
                        value="tryon"
                        checked={selectedPrompt === 'tryon'}
                        onChange={(e) => {
                          setSelectedPrompt(e.target.value);
                          if (e.target.value === 'tryon') {
                            setShowTryOnForm(true);
                          }
                        }}
                        className="form-radio text-blue-600"
                      />
                      <span className="font-medium text-lg">Try On Yourself</span>
                    </label>
                    
                    {selectedPrompt === 'tryon' && (
                      <div className="bg-blue-50 p-4 mt-2 rounded-lg">
                        <div className="flex justify-between items-center mb-4">
                          <div>
                            <h3 className="font-semibold text-gray-800">Virtual Try-On</h3>
                            <p className="text-xs text-gray-600 mt-1">Upload your photo to see how these products look on you!</p>
                          </div>
                        </div>
                        
                        <div className="flex flex-col space-y-4">
                          <div className="border-2 border-dashed border-blue-300 rounded-lg p-6 text-center">
                            <input
                              type="file"
                              accept="image/*"
                              onChange={handleTryOnPhotoUpload}
                              className="hidden"
                              id="tryOnPhotoUpload"
                            />
                            <label htmlFor="tryOnPhotoUpload" className="cursor-pointer">
                              {tryOnPhoto ? (
                                <div className="space-y-2">
                                  <img src={tryOnPhoto} alt="Your Photo" className="w-32 h-32 object-cover rounded-lg mx-auto" />
                                  <p className="text-sm text-green-600 font-medium">Photo uploaded successfully!</p>
                                  <p className="text-xs text-gray-500">Click to change photo</p>
                                </div>
                              ) : (
                                <div className="space-y-2">
                                  <div className="w-16 h-16 bg-blue-200 rounded-full mx-auto flex items-center justify-center">
                                    <span className="text-2xl">ðŸ“·</span>
                                  </div>
                                  <p className="text-sm font-medium text-gray-700">Click to upload your photo</p>
                                  <p className="text-xs text-gray-500">JPG, PNG, or GIF (max 10MB, optimized for AI)</p>
                                </div>
                              )}
                            </label>
                          </div>
                          
                          {tryOnPhoto && (
                            <div className="text-center">
                              <p className="text-sm text-blue-600 font-medium">Ready for virtual try-on!</p>
                              <p className="text-xs text-gray-500 mt-1">AI will dress your photo with the selected products</p>
                            </div>
                          )}
                        </div>
                      </div>
                    )}
                  </div>
                </div>
                <div className="flex justify-end items-center mt-4">
                  <button
                    onClick={handleGenerateImage}
                    disabled={loadingState === 'GENERATING_IMAGE' || (selectedPrompt === 'tryon' && !tryOnPhoto)}
                    className="p-3 bg-blue-600 text-white rounded-lg shadow-md hover:bg-blue-700 transition-all disabled:bg-gray-400 disabled:cursor-not-allowed"
                  >
                    {loadingState === 'GENERATING_IMAGE' ? (
                      <div className="flex items-center justify-center">
                        <svg className="animate-spin -ml-1 mr-3 h-5 w-5 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                          <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
                          <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                        </svg>
                        Generating Image...
                      </div>
                    ) : (selectedPrompt === 'tryon' ? 'Try On Products' : 'Generate Image')}
                  </button>
                </div>
              </div>
            );
          case 4:
            return (
              <div className="flex flex-col items-center space-y-4">
                <h2 className="text-xl font-semibold mb-2">4. Generated Image</h2>
                {generatedImage ? (
                  <img src={generatedImage} alt="Generated Look" className="rounded-lg shadow-lg max-w-full h-auto" />
                ) : (
                  <div className="w-80 h-80 bg-gray-200 rounded-lg flex items-center justify-center">
                    <span className="text-gray-500">Image failed to load</span>
                  </div>
                )}
                <div className="flex space-x-4 mt-6">
                  <button
                    onClick={handleDownloadImage}
                    className="p-3 bg-green-600 text-white rounded-lg shadow-md hover:bg-green-700 transition-all"
                  >
                    Download
                  </button>
                  <button
                    onClick={backToPrompts}
                    className="p-3 bg-gray-600 text-white rounded-lg shadow-md hover:bg-gray-700 transition-all"
                  >
                    Back to Prompts
                  </button>
                  <button
                    onClick={resetApp}
                    className="p-3 bg-blue-600 text-white rounded-lg shadow-md hover:bg-blue-700 transition-all"
                  >
                    Start Over
                  </button>
                </div>
              </div>
            );
          default:
            return null;
        }
      };
    
      const getLoadingMessage = () => {
        switch (loadingState) {
          case 'FETCHING_IMAGES':
            return 'Fetching images from Ounass...';
          case 'GENERATING_PROMPTS':
            return 'Generating AI prompts...';
          case 'UPLOADING_IMAGES':
            return 'Preparing images for AI...';
          case 'GENERATING_IMAGE':
            return 'Generating image, this may take a moment...';
          default:
            return 'Please wait...';
        }
      };
    
      return (
        <div className="min-h-screen bg-gray-100 p-8 flex items-center justify-center font-sans">
          <div className="w-full max-w-3xl bg-white rounded-2xl shadow-xl p-8 transform transition-all duration-300 ease-in-out hover:scale-[1.01] border-4 border-white">
            <div className="flex flex-col items-center text-center mb-8">
              <h1 className="text-4xl font-bold text-gray-800 mb-2">Ounass Look Generator</h1>
              <p className="text-gray-500">Create custom looks from SKU.</p>
              {/* Simplified AI Art Director with direct text extraction */}
              <p className="text-xs text-gray-300 mt-1">v1.9.34</p>
            </div>
    
            {error && (
              <div className="p-4 mb-6 text-sm text-red-700 bg-red-100 rounded-lg text-center font-medium">
                {error}
                <button 
                  onClick={() => setError(null)}
                  className="ml-2 text-red-500 hover:text-red-700 font-bold"
                >
                  Ã—
                </button>
              </div>
            )}
    
            {loadingState !== 'IDLE' && (
              <div className="fixed inset-0 bg-white bg-opacity-75 flex items-center justify-center z-50 p-4">
                <div className="flex flex-col items-center p-6 bg-white rounded-xl shadow-lg">
                  <div className="animate-spin rounded-full h-16 w-16 border-t-4 border-b-4 border-blue-500"></div>
                  <p className="mt-4 text-gray-600 font-semibold">{getLoadingMessage()}</p>
                  
                  {/* Progress indicator for image fetching */}
                  {loadingState === 'FETCHING_IMAGES' && (
                    <div className="mt-4 text-center">
                      <div className="w-64 bg-gray-200 rounded-full h-2 mb-2">
                        <div 
                          className="bg-blue-600 h-2 rounded-full transition-all duration-300"
                          style={{ 
                            width: `${Math.min((Object.keys(productImages).length / Math.max(skus.filter(s => s).length, 1)) * 100, 100)}%` 
                          }}
                        ></div>
                      </div>
                      <p className="text-sm text-gray-500">
                        {Object.keys(productImages).length} of {skus.filter(s => s).length} SKUs processed
                      </p>
                                              <p className="text-xs text-gray-400 mt-1">
                          Loading product images...
                        </p>
                      {Object.keys(productImages).length > 0 && (
                        <div className="mt-2">
                          <p className="text-xs text-green-600 font-medium">
                            âœ“ {Object.keys(productImages).length} SKU(s) loaded successfully!
                          </p>
                          {Object.keys(productImages).length >= 2 && (
                            <p className="text-xs text-blue-600 font-medium">
                              ðŸš€ Ready to proceed to next step!
                            </p>
                          )}
                        </div>
                      )}
                    </div>
                  )}
                  
                  {Object.keys(selectedImages).length > 0 && (
                    <div className="flex flex-wrap gap-4 mt-6">
                      {Object.values(selectedImages).map((src, index) => (
                        <img key={index} src={src} alt="Selected item" className="w-16 h-16 object-cover rounded-md shadow" />
                      ))}
                    </div>
                  )}
                </div>
              </div>
            )}
            
            {renderStep()}
          </div>
        </div>
      );
    };
    
    // Render the App component to the root element
    ReactDOM.render(<App />, document.getElementById('root'));
    
  </script>
  
  <!-- Analytics Status Check -->
  <script>
    // Check if analytics is working
    setTimeout(function() {
      console.log('[Analytics] Status check:');
      console.log('- window.va exists:', typeof window.va !== 'undefined');
      console.log('- Page URL:', window.location.href);
      console.log('- Timestamp:', new Date().toISOString());
      
      // Check network tab for /_vercel/insights requests
      console.log('[Analytics] Check Network tab for /_vercel/insights requests');
    }, 2000);
  </script>
</body>
</html>
